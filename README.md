# Knowledge Transfer for Image Generation Models

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![Hugging Face Diffusers](https://img.shields.io/badge/%F0%9F%A4%97%20Diffusers-v0.21+-FFD21E.svg)

A comprehensive implementation demonstrating knowledge distillation for image generation models. This project specifically focuses on transferring knowledge from a powerful teacher model (Stable Diffusion XL) to a smaller student model (Stable Diffusion 1.5) using Low-Rank Adaptation (LoRA) fine-tuning, with a focus on high-quality dog image generation.

## üìù Overview

This project provides a framework to improve a smaller image generation model (SD 1.5) by learning from images generated by a more capable model (SDXL). The process involves guided fine-tuning using LoRA, specifically tailored for generating diverse and high-quality dog images. It includes extensive evaluation metrics and visualization tools suitable for research purposes.

## ‚ú® Features

* **Knowledge Transfer:** Fine-tune SD 1.5 using SDXL-generated images via LoRA adaptation.
* **Diverse Dataset Generation:** Create datasets using randomly generated prompts covering multiple dog breeds, poses, environments, and lighting conditions.
* **Comprehensive Metrics:** Calculate and compare models using SSIM, MSE, Histogram Similarity, Perceptual Hash Similarity, Sharpness Ratio, and Color Similarity.
* **Research Visualizations:** Generate side-by-side comparison images, difference maps, and detailed metric plots suitable for research papers.
* **Detailed Analysis:** Create radar charts, metric improvement tables, and perform statistical analysis of model enhancements.

## üõ†Ô∏è Requirements

* Python 3.8+
* PyTorch 2.0+
* CUDA-compatible GPU (16+ GB VRAM recommended for efficient training)
* Hugging Face Account & API Token (for downloading base models)
* Approx. 40GB+ disk space (for models, generated images, and metrics - adjust based on `num_iterations`)

**Python Dependencies:**

```python
# Core ML & Diffusers
torch >= 2.0.0
diffusers >= 0.21.4
transformers >= 4.30.0
accelerate >= 0.20.0
# Data & Image Processing
numpy >= 1.24.0
Pillow >= 9.5.0
scikit-image >= 0.20.0
opencv-python >= 4.8.0
# Plotting & Utils
matplotlib >= 3.7.0
huggingface-hub >= 0.16.0
# Add any other specific libraries here (e.g., tqdm, pandas)
```

It is recommended to use a requirements.txt file for easier installation.

## ‚öôÔ∏è Installation
Clone the repository:
```bash
git clone <your-repository-url>
cd <repository-directory>
```

Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate # On Windows use `venv\Scripts\activate`
```

Install dependencies (assuming you create a requirements.txt file from the list above):
```bash
pip install -r requirements.txt
```

Alternatively, install manually:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cuXXX # Replace cuXXX with your CUDA version (e.g., cu118, cu121)
pip install diffusers transformers accelerate numpy matplotlib pillow scikit-image opencv-python huggingface-hub
```

Log in to Hugging Face Hub (if needed for private models or specific versions):
```bash
huggingface-cli login
```

## üöÄ Usage
(Note: Replace script names like generate_data.py, train.py, evaluate.py with the actual names used in your project.)

Configure Parameters: Adjust settings in the main configuration file or script (e.g., config.py or directly in the scripts). See the Configuration section below.

Generate Teacher Data (Optional, if not pre-generated):
(If you have a script to generate images using SDXL)

```bash
python generate_data.py --config <path_to_config>
```
This script would use the defined prompts to generate images using SDXL and save them (e.g., in output/sdxl_images/).

Run LoRA Fine-tuning:

```bash
python train.py --config <path_to_config>
```
This script will fine-tune the SD 1.5 model using the generated SDXL images and LoRA, saving checkpoints (e.g., in output/checkpoints/).

Evaluate and Compare Models:

```bash
python evaluate.py --config <path_to_config> --checkpoint <path_to_lora_checkpoint>
```
This script generates images using the original SD 1.5 and the fine-tuned version, calculates all metrics, and saves the results (e.g., in output/metrics/, output/comparison_output/, output/research_comparisons/).

Visualize Results:
(This might be part of the evaluation script or a separate one)

```bash
python visualize.py --metrics_dir output/metrics/ --output_dir output/visualization/
```
This script creates charts (like radar charts, bar plots) and summary visualizations based on the calculated metrics.

## üìÅ Project Structure (Output Directory)
The project generates the following output structure (example):


## Output 

‚îú‚îÄ‚îÄ checkpoints/ # Saved LoRA model weights during training
‚îú‚îÄ‚îÄ comparison_output/ # Side-by-side image comparisons (Before vs. After fine-tuning)
‚îú‚îÄ‚îÄ metrics/ # Raw metric data (e.g., CSV or JSON files)
‚îú‚îÄ‚îÄ research_comparisons/ # Detailed comparison images (diff maps, etc.) for research
‚îú‚îÄ‚îÄ research_paper_materials/# Summary reports, key figures, and analysis outputs (e.g., markdown summaries)
‚îú‚îÄ‚îÄ sdxl_images/ # High-quality reference images generated by SDXL (Teacher)
‚îú‚îÄ‚îÄ visualization/ # Generated charts, graphs, and summary plots
‚îî‚îÄ‚îÄ weakmodel_images/ # Images generated by the baseline SD 1.5 model (Before fine-tuning)


## üîß Configuration
Key experiment parameters are typically defined in a central configuration dictionary or file (e.g., config.py or at the top of the main script).

Example CONFIG (adjust values as needed):

```python
CONFIG = {
    # --- Data Generation ---
    "prompt_source": "path/to/prompts.csv", # Or define generation parameters
    "num_images_to_generate": 1000,      # Number of SDXL images for training dataset

    # --- Training ---
    "base_model_id": "runwayml/stable-diffusion-v1-5",
    "teacher_model_id": "stabilityai/stable-diffusion-xl-base-1.0", # Used for reference if needed during eval
    "sdxl_image_dir": "output/sdxl_images/", # Directory containing teacher images
    "output_dir": "output/",
    "seed": 42,
    "resolution": 512,
    "train_batch_size": 4,          # Adjust based on VRAM
    "num_train_epochs": 10,
    "learning_rate": 1e-4,
    "lr_scheduler": "cosine",       # e.g., "linear", "cosine", "constant"
    "mixed_precision": "fp16",      # "no", "fp16", "bf16"
    "gradient_accumulation_steps": 1,

    # --- LoRA Specific ---
    "use_lora": True,
    "lora_r": 16,                   # Rank of LoRA matrices
    "lora_alpha": 32,               # Scaling factor for LoRA
    "lora_dropout": 0.1,
    "lora_target_modules": ["q_proj", "v_proj", "k_proj", "out_proj", "fc1", "fc2"], # Example for CLIP text encoder

    # --- Inference & Evaluation ---
    "eval_batch_size": 1,
    "num_inference_steps": 50,
    "guidance_scale": 7.5,
    "num_evaluation_prompts": 100, # Number of prompts to use for evaluation metrics
}
```

## üìä Metrics and Evaluation
The evaluation script calculates and visualizes multiple image quality and similarity metrics between the baseline SD 1.5 generations and the fine-tuned model's generations, often using the SDXL images as a reference point where applicable.

- SSIM (Structural Similarity Index): Measures perceived structural similarity.
- MSE (Mean Squared Error): Calculates pixel-level differences.
- Histogram Similarity: Compares color distributions (e.g., using Bhattacharyya distance or correlation).
- Perceptual Hash (pHash) Similarity: Measures overall visual similarity based on image hashes.
- Sharpness Ratio: Compares image clarity and detail (e.g., using Laplacian variance).
- Color Similarity: Assesses color distribution consistency (e.g., comparing dominant colors or color moments).

Results are saved numerically (e.g., CSV/JSON) and visualized through plots and comparison images.

## üî¨ Research Applications
This framework is particularly useful for research tasks, such as:

- Investigating knowledge transfer techniques for generative models.
- Evaluating the effectiveness of LoRA for distilling large diffusion models.
- Quantifying the improvement in smaller models trained with guidance from larger ones.
- Generating high-quality figures, metrics, and comparative analyses for publications.
- Studying the impact of different distillation strategies on specific image attributes (e.g., style, composition, detail).

## üß© Code Structure / Workflow
The project code is typically organized into logical components:

- Data Generation: Scripts or functions to create diverse prompts and generate high-quality reference images using the teacher model (SDXL).
- LoRA Implementation: Configuration and application of LoRA layers to the student model (SD 1.5). Often leverages libraries like peft.
- Training Loop: Efficient training pipeline, potentially using accelerate for handling device placement, gradient accumulation, and mixed precision.
- Evaluation: Scripts to generate images from both baseline and fine-tuned models, calculate defined metrics against reference images or prompts.
- Visualization: Functions to create comparison grids, difference maps, metric plots (radar charts, bar plots), and statistical summaries.
- Analysis: Potentially includes scripts to aggregate results and generate summary reports (e.g., a markdown file in research_paper_materials/).

## üìÑ License
This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgements
- Stability AI for the Stable Diffusion models.
- Hugging Face for the diffusers, transformers, and accelerate libraries, and model hosting.
- The PyTorch Team for the deep learning framework.
- Contributors to the LoRA and PEFT methods.

